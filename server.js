import 'dotenv/config';
import express from 'express';
import cors from 'cors';
import OpenAI from 'openai';

const app = express();
app.use(cors());
app.use(express.json());

const client = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

const SYSTEM_MESSAGE = {
  role: "system",
  content: `
    Ð¢Ð¸ LUMI â€” Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð»ÑŒÐ½Ð¸Ð¹ AI-Ð¿Ð¾Ð¼Ñ–Ñ‡Ð½Ð¸Ðº.
    ÐÐµ Ð·Ð³Ð°Ð´ÑƒÐ¹ ChatGPT, OpenAI Ð°Ð±Ð¾ Ð¼Ð¾Ð´ÐµÐ»Ñ–.
    Ð’Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð°Ð¹ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¾, Ð´Ñ€ÑƒÐ¶Ð½ÑŒÐ¾, ÑÐº Ð»ÑŽÐ´Ð¸Ð½Ð°.
  `
};

app.post("/api/chat", async (req, res) => {
  try {
    const messages = [SYSTEM_MESSAGE, ...(req.body.messages || [])];

    const completion = await client.chat.completions.create({
      model: "gpt-4o-mini",
      messages
    });

    let reply = "";

    if (completion.choices?.[0]?.message?.content) {
      reply = completion.choices[0].message.content;
    } else if (completion.choices?.[0]?.message) {
      reply = completion.choices[0].message;
    } else {
      reply = "LUMI Ð½Ñ–Ñ‡Ð¾Ð³Ð¾ Ð½Ðµ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð² ðŸ˜¢";
    }

    res.json({ reply });

  } catch (e) {
    console.error("SERVER ERROR:", e);
    res.status(500).json({ error: "ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€Ñ– LUMI" });
  }
});

const PORT = process.env.PORT || 3000;
app.listen(PORT, () =>
  console.log(`LUMI backend running on port ${PORT}`)
);
